{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Console](https://www.tight.ai/login) | [SDK](https://www.tight.ai/sdk) | [Docs](https://www.tight.ai/docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is simply a computer learning from data instead of following a recipe. It's meant to mimic how people (and perhaps other animals) learn while still being grounded in mathematics.\n",
    "\n",
    "This post is meant to get you started with a basic machine learning model. \n",
    "\n",
    "A chatbot.\n",
    "\n",
    "Now, we're not re-creating Alexa, Siri, Cortana, or Google Assistant but we are going to create a brand new machine learning program from scratch. \n",
    "\n",
    "This tutorial is meant to be easy assuming you know a bit of Python Programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: What's our data?\n",
    "\n",
    "Machine learning needs data to actually, well, learn. Machines don't yet learn like you and I do but they do learn by finding patterns in things that may seem non-obvious to you and I. We'll see a lot of that in this entire post.\n",
    "\n",
    "Before we define our data, let's talk about the goal of this ML (machine learning) project:\n",
    ">  To answer somewhat \"random\" questions with pre-defined responses.\n",
    "\n",
    "\n",
    "Here's what we'll try and solve:\n",
    "\n",
    "__Scenario 1__\n",
    "\n",
    "Bill: `Hi there, what time do you open tomorrow for lunch?`\n",
    "\n",
    "Bot: `Our hours are 9am-10pm everday.`\n",
    "\n",
    "\n",
    "__Scenario 2__\n",
    "\n",
    "Karen: `Can I speak to your manager?`\n",
    "\n",
    "Bot: `You can contact our customer support at 555-555-555.5`\n",
    "\n",
    "\n",
    "__Scenario 3__\n",
    "\n",
    "Wade: `What type of products do you have?`\n",
    "\n",
    "Bot: `We carry various food items including tacos, nachos, burritos, and salads.`\n",
    "\n",
    "Let's put this into a python format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = [\n",
    "    {\n",
    "        \"customer\": \"Hi there, what time do you open tomorrow for lunch?\",\n",
    "        \"response\": \"Our hours are 9am-10pm everday.\"\n",
    "    },\n",
    "     {\n",
    "        \"customer\": \"Can I speak to your manager?\",\n",
    "        \"response\": \"You can contact our customer support at 555-555-5555.\"\n",
    "    },\n",
    "     {\n",
    "        \"customer\": \"What type of products do you have?\",\n",
    "        \"response\": \"We carry various food items including tacos, nachos, burritos, and salads.\"\n",
    "    }  \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without machine learning our bot would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    customer_input = input(\"What is your question?\\n\")\n",
    "    response = None\n",
    "    for convo in conversations:\n",
    "        if convo['customer'] == customer_input:\n",
    "            response =  convo['response']\n",
    "    if response != None:\n",
    "        print(response)\n",
    "        break\n",
    "    continue        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away, you should see the huge flaws in this recipe; if a customer doesn't ask a question in a specific pre-defined way, the bot fails and ultimately really sucks. \n",
    "\n",
    "A few examples:\n",
    "    - What if a customer says, _when do you open?_ What do you already know the response to be? \n",
    "    - What if a customer says, _Do you sell burgers?_\n",
    "    - What if a customer says, _How do I reach you on the phone?_\n",
    "   \n",
    "I'm sure you could come up with many many more examples of where this really falls apart.\n",
    "\n",
    "So let's clean up our converstaions data a bit more by adding `tags` that describe the initial question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_tagged = [\n",
    "    {\n",
    "        \"customer\": \"Hi there, what time do you open tomorrow for lunch?\",\n",
    "        \"tags\": ['opening', 'hours'],\n",
    "    },\n",
    "     {\n",
    "        \"customer\": \"Can I speak to your manager?\",\n",
    "        \"tags\": ['contact', 'customer_support'],\n",
    "    },\n",
    "     {\n",
    "        \"customer\": \"What type of products do you have?\",\n",
    "        \"tags\": ['products', 'inventory'],\n",
    "    }     \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I removed the responses on purpose. Machine learning needs \"input\" data and \"output\" data. In this case, we're interested in the \"essence\" of what a customer is asking. Yes, bots can get MUCH more complex than this but we just want to essentially \"auto-tag\" when a customer asks a question.\n",
    "\n",
    "A few examples:\n",
    "    - What if a customer says, _when do you open?_ We want our ML app to guess at least `opening` as a tag. \n",
    "    - What if a customer says, _Do you sell burgers?_ We want our ML app to guess at least `inventory` as a tag.\n",
    "    - What if a customer says, _How do I reach you on the phone?_ We want our ML app to guess at least `contact` as a tag.\n",
    " \n",
    " \n",
    "Once we know a tag, we can write in \"recipes\" on how to handle that tag. Something like:\n",
    "    - If the tag is `opening`, then we can respond with `We're open from 9am-10pm Monday-Sunday` OR `Our hours are 9am-10pm everday.`\n",
    "\n",
    "Notice that I added a `OR` option to the potential response? This ability with give the bot a bit more natural feeling.\n",
    "\n",
    "Okay. Now let's create a few more tagged conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convos_two = [\n",
    "    {\n",
    "        \"customer\": \"How late is your kitchen open?\",\n",
    "        \"tags\": ['opening', 'hours'],\n",
    "    },\n",
    "     {\n",
    "        \"customer\": \"My order was prepared incorrectly, how can I get this fixed?\",\n",
    "        \"tags\": ['customer_support'],\n",
    "    },\n",
    "    {\n",
    "        \"customer\": \"The food was amazing. Thank you!\",\n",
    "        \"tags\": ['feedback', 'customer_support'],\n",
    "    },\n",
    "    {\n",
    "        \"customer\": \"What kind of meats do you have?\",\n",
    "        \"tags\": ['menu', 'products', 'inventory'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see a trend happening here? It's really easy to come up with all kinds of questions for a restaurant bot. It's also easy to see how challenging this would be to try and hard-code conditions to handle all the kinds of queries/questions customers could have.\n",
    "\n",
    "I'm sure you've heard you need a LOT of data for machine learning. I'll just add one thing to that, you need a lot of data to have *awe-inspiring* machine learning projects. A simple bot for a mom-and-pop store down the street doesn't need *awe-inspiring* just yet. They need simple, approachable, easy to explain. That's exactly what this is. It's not a black box of *millions* of lines of data points. It's like 20 questions with made up on the spot tags.\n",
    "\n",
    "In so many ways, machine learning today (in the 2020s) is like the internet of the 1990s. People have heard about it and \"sort of get it\" and feel like it's just this magical gemmick that only super nerds know how to do. Ha. Super nerds.\n",
    "\n",
    "Now that we have our starting data, let's prepare for machine learning.\n",
    "\n",
    "First, let's combine all converstaions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_convos = conversations_tagged + convos_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For good measure, let's add a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convos_three = [\n",
    "    {\n",
    "        \"customer\": \"When does your dining room open?\",\n",
    "        \"tags\": ['opening', 'hours'],\n",
    "    },\n",
    "     {\n",
    "        \"customer\": \"When do you open for dinner?\",\n",
    "        \"tags\": ['opening', 'hours'],\n",
    "    },\n",
    "    {\n",
    "        \"customer\": \"How do I contact you?\",\n",
    "        \"tags\": [\"contact\", \"customer_support\"]\n",
    "    }\n",
    "]\n",
    "final_convos += convos_three\n",
    "\n",
    "final_convos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our conversations have the keys `customer` and `tags`. These are artibtaray names for this project and you change change them at-will. Just remember that `customer` equals `input` and `tags` equals `output`. This makes sense because in the future, we want a random customer input such as `What's the menu specials today` and a predicted tags output like `menu` or something similar.\n",
    "\n",
    "\n",
    "Machine learning has all kinds of terms and acyronyms that often make it a bit confusing. In general, just remember that you have some `inputs` and some target `outputs`. Here's what I mean by that:\n",
    "\n",
    "- `customer`: These values are really the `input` values for our ML project. Input values are sometimes called `source`, `feature`, `training`, `X`, `X_train`/`X_test`/`X_valid`, and a few others.\n",
    "- `tags`: These values are really the `output` values for our ML project. Output values are sometimes called `target`, `labels`, `y`, `y_train`/`y_test`/`y_valid`, `classes`/`class`, and a few others.\n",
    "\n",
    "> We're using a machine learning technique known as `supervised learning` which means we provide both the `inputs` and `outputs` to the model. Both data points are known data that we came up with. As you know, the `tags` (or `labels`/`outputs`) have been decided by a human (ie you and me) but can, eventually, be decied by a ML model itself and then verified by a human. Doing so would make the model better and better. There are many other techniques but `supervised learning` is by far the most approachable for beginners.\n",
    "\n",
    "\n",
    "### Prepare for ML\n",
    "\n",
    "Now that we have our data, it's time to put it into a format that works well for computers. As you may know, computers are great at numbers and not so great at text. In this case, we have to convert our text into numbers.\n",
    "\n",
    "\n",
    "This is made simple by using the [scikit-learn](https://scikit-learn.org/stable/index.html) library. So let's install it below by uncommenting the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First up, let's turn our `customer` and `tag` data into 2 separate lists where the index of each item corresponds to the index of the other.\n",
    "\n",
    "```\n",
    "X = [customer_convo_1, customer_convo_2, ...]\n",
    "y = [convo_1_tags, convo_2_tags, ...]\n",
    "```\n",
    "\n",
    "This is very standard practice so that `X[0]` is the `input` that corresponds to the `y[0]` `output`, `X[1]` is the `input` that corresponds to the `y[1]` `output` and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [x['customer'] for x in final_convos]\n",
    "outputs = [x['tags'] for x in final_convos]\n",
    "\n",
    "assert len(inputs) == len(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you have an `AssertionError` above, that means your `inputs` and `outputs` are not balanced. Check your data source(s) to ensure every `input` has a corresponding `output` value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to turn each `inputs` list and `outputs` list into a list of `numbers` so our machine learning can do machine learning. \n",
    "\n",
    "`scikit-learn` has a simple way to do this. First, let's focus on the `inputs` (aka `customer` conversations) as they are the most simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Inputs (`features`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initialize our vectorizer.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Technical note: `scikit-learn` converted our data into a collection of 1 dimension matrices. We need to use matrices so we can do matrix multiplication (that's how machine learning works under the hood). In `numpy` speak, `X` is an `array` of `array`s.  If you want to see the actual vectors created, check out `X.toarray()` and you'll see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X.shape` is useful to describe our data. \n",
    "\n",
    "`X.shape[0]` refers to the number of conversations from our `final_convos` list. So, `X.shape[0] == len(final_convos)` and `X.shape[0] == len(inputs)`\n",
    "\n",
    "\n",
    "`X.shape[1]` refers to the number of `words` our data has. The `CountVectorizer` did this for us. The Machine Learning term is `feactures` related to what our data has. You can see all of the `features` (`words` minus punctuation) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorizer has a very limited vocabulary as you can see. Naturally, this means our ML project will *always* missunderstand some key converstaions and that's okay. The goal for our project is to get it working first, get customers (or ourselves) using it so we can *improve* it with new data right away (and thus re-improve it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Outputs (`labels`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every one of our inputs has a list of tags, not just one tag. Let's look at what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs[0], outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, this means `multi-label` classification because there are multiple `output` values for each `input` value. This is a more challenging problem than a `single` label but definitely necssary for a chatbot project.\n",
    "\n",
    "A single label dataset would look like the following:\n",
    "```\n",
    "Input: Hi there, how are you doing today?\n",
    "Output: not_spam\n",
    "\n",
    "Input: Free CELL phones just text 3ED#2\n",
    "Output: spam\n",
    "```\n",
    "\n",
    "Notice that the output is a single `str` and not a `list` of `str` values. If we continued down this path, our data would *always* fall into 2 categories: `spam` or `not_spam`.\n",
    "\n",
    "\n",
    "In our project, our `input` values *can* fall into multiple values, 1 value, or no values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `mlb.classes_` gives us the exact order of how our classes are defined in `y`. So `y[0]` corrensponds to `outputs[0]` but in numbers instead of words. It's pretty cool. To see this technically, run the following code:\n",
    "\n",
    "```\n",
    "print(y[0])\n",
    "# map to classes with `zip`\n",
    "y0_mapped_to_classes = dict(zip(mlb.classes_, y[0]))\n",
    "print(y0_mapped_to_classes)\n",
    "```\n",
    "\n",
    "Then compare:\n",
    "```\n",
    "sorted(outputs[0]) == sorted([k for k,v in y0_mapped_to_classes.items() if v == 1])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y.shape` is useful to describe our data in a similar way to `X.shape`\n",
    "\n",
    "`y.shape[0]` refers to the number of conversations from our `final_convos` list. So, `y.shape[0] == len(final_convos)` and `y.shape[0] == len(outputs)` and `y.shape[0] == X.shape[0]`\n",
    "\n",
    "\n",
    "`y.shape[1]` refers to the unique values of all of the possible `tags` each converstaion has; it will never repeat using the `MultiLabelBinarizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y.shape[0] == X.shape[0]\n",
    "assert y.shape[0] == len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see an `AssertionError` here, it's the same exact error as `assert len(inputs) == len(outputs)` from above. Your data is not balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with `scikit-lean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(random_state=1)\n",
    "model = MultiOutputClassifier(forest, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual training\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mlb.classes_\n",
    "def label_predictor(text=\"Hello World\", model=None, vectorizer=None):\n",
    "    assert model != None\n",
    "    assert vectorizer != None\n",
    "    x_test = vectorizer.transform([text])\n",
    "    target = model.predict(x_test)\n",
    "    preds = {}\n",
    "    for i, val in enumerate(target[0]):\n",
    "        preds[classes[i]] = val\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predictor(\"How do I contact your manager?\",  model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_predictor(\"Hello world\",  model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Model for Re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "NB_ROOT = pathlib.Path(\"\").resolve()\n",
    "PROJECTS_ROOT = NB_ROOT.parent / \"projects\"\n",
    "PROJECT_NAME = 'hello-world'\n",
    "PROJECT_PATH = PROJECTS_ROOT / PROJECT_NAME\n",
    "PROJECT_DATA = PROJECT_PATH / \"data\"\n",
    "if not PROJECT_DATA.exists():\n",
    "    \"project does not exist locally, make all folders\"\n",
    "    PROJECT_DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pickle_dest = PROJECT_DATA / 'model.pkl'\n",
    "pickle_object = {\n",
    "    \"model\": model,\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"classes\": mlb.classes_\n",
    "}\n",
    "\n",
    "with open(pickle_dest, 'wb') as f:\n",
    "    pickle.dump(pickle_object, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-use Exported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "NB_ROOT = pathlib.Path(\"\").resolve()\n",
    "PROJECTS_ROOT = NB_ROOT.parent / \"projects\"\n",
    "PROJECT_NAME = 'hello-world'\n",
    "PROJECT_PATH = PROJECTS_ROOT / PROJECT_NAME\n",
    "PROJECT_DATA = PROJECT_PATH / \"data\"\n",
    "if not PROJECT_DATA.exists():\n",
    "    \"project does not exist locally, make all folders\"\n",
    "    PROJECT_DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pickle_source = PROJECT_DATA / 'model.pkl'\n",
    "\n",
    "loaded_pickle_obj = None\n",
    "\n",
    "with open(pickle_source, 'rb') as f:\n",
    "    loaded_pickle_obj = pickle.loads(f.read())\n",
    "    \n",
    "classes = loaded_pickle_obj['classes']\n",
    "label_predictor(\"I did enjoy my meal\", loaded_pickle_obj['model'], loaded_pickle_obj['vectorizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ENTRY = PROJECT_PATH/\"entry.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $PROJECT_ENTRY\n",
    "\n",
    "import sklearn\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "BASE_DIR = pathlib.Path(__file__).parent.absolute()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "SOURCE_PKL = DATA_DIR / 'model.pkl'\n",
    "\n",
    "classes = []\n",
    "model = None\n",
    "vectorizer = None\n",
    "\n",
    "def load_pickle_data():\n",
    "    global classes\n",
    "    global model\n",
    "    global vectorizer\n",
    "    with open(SOURCE_PKL, 'rb') as f:\n",
    "        loaded_pickle_obj = pickle.loads(f.read())\n",
    "        classes = loaded_pickle_obj['classes']\n",
    "        model = loaded_pickle_obj['model']\n",
    "        vectorizer = loaded_pickle_obj['vectorizer']\n",
    "        \n",
    "        \n",
    "\n",
    "load_pickle_data()\n",
    "\n",
    "def label_predictor(text=\"Hello World\"):\n",
    "    global classes\n",
    "    global model\n",
    "    global vectorizer\n",
    "    x_test = vectorizer.transform([text])\n",
    "    target = model.predict(x_test) # target is an array of numpy.int64, we need a python `int` instead\n",
    "    preds = {}\n",
    "    for i, val in enumerate(target[0]):\n",
    "        key_label = classes[i]\n",
    "        preds[key_label] = int(val) # convert numpy.int64 into a python `int`\n",
    "    return preds\n",
    "\n",
    "def run(json_data={}, *args, **kwargs):\n",
    "    '''\n",
    "    Required method for tight.ai serving\n",
    "    Returns a dictionary that is `json.dumps` ready.\n",
    "    '''\n",
    "    \n",
    "    if 'question' not in json_data:\n",
    "        return {'message': \"a question is required\", 'status': 400}\n",
    "    input_question = json_data.get('question')\n",
    "    tags = label_predictor(text=input_question)\n",
    "    return {\n",
    "        \"question\": input_question,\n",
    "        \"tags\": tags\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Local Server via Tight.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PORT = 5008\n",
    "print(\"Copy the result of the following into your terminal / powershell:\\n\\n\")\n",
    "print(f\"tight local run --path {PROJECT_PATH} --port {LOCAL_PORT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can also run this command within jupyter by adding a `!` in front of it like `!tight local run `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    \"question\": \"When do you open tomorrow?\"\n",
    "}\n",
    "\n",
    "r = requests.post(\"http://localhost:5008\", json=data)\n",
    "print(\n",
    "    r.json()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an [API KEY](https://www.tight.ai/developer/tokens/) from https://www.tight.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the only requirement we need `scikit-learn`\n",
    "\n",
    "REQUIREMENTS_OUTPUT = PROJECT_PATH / \"requirements.txt\"\n",
    "!echo \"scikit-learn\" > $REQUIREMENTS_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "my_api_key = getpass.getpass(f\"Enter your api key from https://www.tight.ai/developer/tokens/\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tightai\n",
    "tightai.api_key = my_api_key or \"<your_api_key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tightai.projects import Project\n",
    "Project.get_http_headers()\n",
    "projects = Project.objects.all()\n",
    "projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Your Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tightai.projects import Project\n",
    "\n",
    "project_name = \"hello-world\"\n",
    "# project_obj = Project.objects.create(project_id=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Push Into Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tightai.projects import Project\n",
    "\n",
    "project_name = \"hello-world\" # or whatever you choose\n",
    "\n",
    "# Get our just-created Project\n",
    "project_obj = Project.objects.get(project_id=project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the latest project version or by number\n",
    "version_obj = project.latest()\n",
    "\n",
    "# or\n",
    "# version_obj = project_obj.get_version(version=1)\n",
    "\n",
    "# or\n",
    "\n",
    "# from tightai.projects import Version\n",
    "# version_obj = Version.objects.get(project_id='hello-world', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push your code\n",
    "version_obj.push(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get deployment status\n",
    "version_obj.status(latest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predictions\n",
    "\n",
    "# directly on version object.\n",
    "version_obj.predict(json={'question': \"What time do you open?\"})\n",
    "\n",
    "# or with latest project version\n",
    "# project_obj.predict(json={'question': \"What time do you open?\"}, use_latest=True)\n",
    "\n",
    "# or with Project version number\n",
    "# project_obj.predict(json={'question': \"What time do you open?\"}, version=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
